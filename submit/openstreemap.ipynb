{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenStreetMap Data Wrangling with MongoDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kai Wang\n",
    "\n",
    "Map Area: Beijing, China\n",
    "\n",
    "*https://s3.amazonaws.com/metro-extracts.mapzen.com/beijing_china.osm.bz2*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Problems Encountered in the Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After downloading the xml file and running test.py to see the general idea of the data, four  main problems were noticed.\n",
    "\n",
    "+ Over-abbreviated street names (\"Dongzhimen Outer **St**\").\n",
    "+ There is wrong postcode, perhaps phone number(010-62332281).\n",
    "+ A variety of different forms of fax and phone ('+86 10 5960 2233',  '+86-010-69079600',  '86-10-64577779',  '(+86)10/65125126').\n",
    "+ Multiple key have the same meaning (疏散人数（万）, 应急避难场所疏散人数万人, 疏散人数, 应急避难场所疏散人口万人)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Over-abbreviated street\n",
    "\n",
    "For those over-abbreviated address, we updated using function *correct_street_type* in audit.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def correct_street_type(street_name):\n",
    "    changed = 0\n",
    "    street_name = street_name.strip()\n",
    "    words = street_name.split()\n",
    "    newwords = ''\n",
    "    # change street abbreviation to full name\n",
    "    for w in words:\n",
    "        if w in mapping:\n",
    "            newwords += mapping[w] + ' '\n",
    "        else:\n",
    "            newwords += w + ' '\n",
    "    if street_name != newwords[:-1]:\n",
    "        #print street_name + '=>' + newwords[:-1]\n",
    "        changed = 1\n",
    "\n",
    "    return newwords[:-1], changed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### wrong postcode\n",
    "\n",
    "This is phone-format string in postcode tag: \"010-62332281\". Maybe it's a wrong input by mistake. So we can easily ignore this wrong input by detecting \"-\" and skip this tag value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fix fax and phone formate\n",
    "\n",
    "There are quite a lot of different forms of fax and phone(('+86 10 5960 2233',  '+86-010-69079600',  '86-10-64577779',  '(+86)10/65125126'),'+86 10 8438 8088') and some tag value contain two number separated by \";\" or \"/\". The '/' is very tricky because there are also number like:\"(+86)10/65133366\", which should be treated as one number. But \"00861065323114/008613901017417\" should be split into two numbers. Function *correct_number* were write to deal with the fax and phone tags."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiple key have the same meaning\n",
    "\n",
    "\"应急避难场所疏散人数万人\" and \"应急避难场所疏散人口万人\" are two k tags that have the same meaning. They all mean \"the number of people that a emergency shelter can has (10 thousands unit)\". \"疏散人数（万）\" and \"疏散人数\" also have similar meaning: \"number of people can be  evacuated\". But the former is 10 thousands unit. So the former is the later divied by 10000. This can be due to inputting the same item by different people. We will combine the similar keys in data.py."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After downloaded and uncompressed the data file, we can see that it's not quite a large dataset, but big enough to force us to consider using cElementTree and iterate through the data instead of reading all into memory.\n",
    "\n",
    "    $ du -sh beijing_china.osm\n",
    "    152M    beijing_china.osm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic statistics about the dataset were fetched by MongoDB queries and listed below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 817151\n",
      "Number of nodes: 711770\n",
      "Number of ways: 105369\n",
      "Number of unique users: 1374\n",
      "Top 10 contributing user:\n",
      "\tChen Jia: 194010\n",
      "\tR438: 151265\n",
      "\tij_: 52067\n",
      "\thanchao: 47770\n",
      "\tkatpatuka: 24074\n",
      "\tm17design: 21999\n",
      "\tEsperanza36: 19123\n",
      "\tnuklearerWintersturm: 17233\n",
      "\tRationalTangle: 14493\n",
      "\tu_kubota: 9411\n",
      "Number of users appearing only once: 275\n"
     ]
    }
   ],
   "source": [
    "import  pymongo\n",
    "client = pymongo.MongoClient('192.168.32.200', 27017)\n",
    "db = client['test']\n",
    "db.authenticate('test','test')\n",
    "\n",
    "# Number of documents\n",
    "doccount = db.openstreet.find().count()\n",
    "print \"Number of documents: %d\" % doccount\n",
    "# Number of nodes\n",
    "nodecount = db.openstreet.find({\"type\":\"node\"}).count()\n",
    "print \"Number of nodes: %d\" % nodecount\n",
    "# Number of ways\n",
    "waycount = db.openstreet.find({\"type\":\"way\"}).count()\n",
    "print \"Number of ways: %d\" % waycount\n",
    "# Number of unique users\n",
    "uniqusers = len(db.openstreet.distinct(\"created.user\"))\n",
    "print \"Number of unique users: %d\" % uniqusers\n",
    "#Top 10 contributing user\n",
    "R = db.openstreet.aggregate([{\"$group\":{\"_id\":\"$created.user\", \"count\":{\"$sum\":1}}}, {\"$sort\":{\"count\":-1}}, {\"$limit\":10}])\n",
    "print \"Top 10 contributing user:\"\n",
    "for r in R:\n",
    "    print '\\t' + r['_id'] + ': ' +  str(r['count'])\n",
    "# Number of users appearing only once (having 1 post)\n",
    "R = db.openstreet.aggregate([{\"$group\":{\"_id\":\"$created.user\", \"count\":{\"$sum\":1}}}, {\"$group\":{\"_id\":\"$count\", \"num_users\":{\"$sum\":1}}}, {\"$sort\":{\"_id\":1}}, {\"$limit\":1}])\n",
    "for r in R:\n",
    "    print \"Number of users appearing only once: %d\" % r[\"num_users\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Additional Ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mix-use of Chinese and English\n",
    "\n",
    "In some tag, Chinese and English words are mixed together. Like the stree name listed below. It's better to create streetName_en and streetName_ch to store English street name and Chinese street name separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学院路\n",
      "团结湖北口\n",
      "Wangfuijing Street\n",
      "新街口外大街\n",
      "西二旗大街\n",
      "林萃路\n",
      "酒仙桥北路 甲10号院电子城IT产业园107楼6层\n",
      "荷清路\n",
      "中关村大街\n",
      "北四环中路\n"
     ]
    }
   ],
   "source": [
    "sR = db.openstreet.distinct(\"address.street\")\n",
    "for s in sR[:10]:\n",
    "    print s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides the translation work, the different format of phone numbers and fax numbers also reflect the lack of standard format. Although community curation will join unimaginable efforts to the public database, we should be also aware that different people have different input habit and that should not be include in the database. A standard format document may help to guild contributors to have a standardized entries. And also a automatic check of the format of a new entry is also a good way. Both of the improvements need a lot more efforts, like draft a standardized document and writing validation code for new entries. It will be a lot of work for a public source."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Additional data exploration using MongoDB queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 appearing amenities:\n",
      "restaurant: 1016\n",
      "parking: 613\n",
      "bank: 362\n",
      "school: 350\n",
      "toilets: 332\n",
      "fuel: 276\n",
      "fast_food: 256\n",
      "cafe: 182\n",
      "hospital: 156\n",
      "telephone: 150\n"
     ]
    }
   ],
   "source": [
    "# Top 10 appearing amenities\n",
    "amenitiesR = db.openstreet.aggregate([{\"$match\":{\"amenity\":{\"$exists\":1}}}, {\"$group\":{\"_id\":\"$amenity\",\"count\":{\"$sum\":1}}}, {\"$sort\":{\"count\":-1}}, {\"$limit\":10}])\n",
    "print \"Top 10 appearing amenities:\"\n",
    "for r in amenitiesR:\n",
    "    print r[\"_id\"] + ': ' + str(r['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biggest religion:\n",
      "buddhist: 40\n"
     ]
    }
   ],
   "source": [
    "# Biggest religion\n",
    "religionR = db.openstreet.aggregate([{\"$match\":{\"amenity\":{\"$exists\":1}, \"amenity\":\"place_of_worship\"}},\n",
    "                   {\"$group\":{\"_id\":\"$religion\", \"count\":{\"$sum\":1}}},\n",
    "                   {\"$sort\":{\"count\":-1}}, {\"$limit\":1}])\n",
    "print \"Biggest religion:\"\n",
    "for r in religionR:\n",
    "    print r[\"_id\"] + ': ' + str(r['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most popular cuisines:\n",
      "chinese: 115\n",
      "japanese: 11\n",
      "pizza: 10\n",
      "regional: 10\n",
      "italian: 8\n",
      "international: 5\n",
      "american: 4\n",
      "asian: 3\n",
      "german: 3\n",
      "thai: 3\n"
     ]
    }
   ],
   "source": [
    "# Most popular cuisines\n",
    "cuisinesR = db.openstreet.aggregate([{\"$match\":{\"amenity\":{\"$exists\":1},\"cuisine\":{\"$exists\":1},\"amenity\":\"restaurant\"}}, \n",
    "                   {\"$group\":{\"_id\":\"$cuisine\", \"count\":{\"$sum\":1}}},\n",
    "                   {\"$sort\":{\"count\":-1}}, {\"$limit\":10}])\n",
    "print \"Most popular cuisines:\"\n",
    "for r in cuisinesR:\n",
    "    print str(r[\"_id\"]) + ': ' + str(r['count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 755 restaurants don't have a \"cuisine\" tag. But it's pretty mush the case that most Chinese love Chinese Food."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Conclusion  \n",
    "\n",
    "We've import the OpenStreetMap data of Beijing into MongoDB. Although it can be called \"clean data\", we should keep in mind that there's still possible that some mistake in the data. Maybe after further use of it, we will be forced to come back and add more clean functions. But for now, it looks fine. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
